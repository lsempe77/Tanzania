---
title: "Mokoro - Tanzania"
output:
  word_document: default
  html_notebook: default
  pdf_document:
    latex_engine: xelatex
    number_sections: yes
editor_options:
  chunk_output_type: console
---

```{r, options, echo=F}

knitr::opts_chunk$set(echo = FALSE, warning = F,message = F,fig.pos="H",tinytex.verbose = TRUE)

```


```{r, packages}

setwd("C:/Users/LUCAS/Desktop/Tanzania")


library(tidyverse)
library(dplyr)
library(readxl)
library(broom)
library(tabulizer)
library(rmarkdown)
library(haven)
library(hablar)
library(lme4)
library(lmerTest)
library(sjstats)
library(ggpubr)
library(lmtest)
library(plm)
library(pander)

options(scipen = 3)

```

```{r}
panderOptions('digits',3)

panderOptions('table.continues',F)

```

# Data

`lgacontrols`: 89 variables ranging from population, poverty, goverment expenditure,
data on educational system. Data ranges from 2015-2019. Not all data has complete series.

```{r, lga controls}

lgacontrols <- read_excel("C:/Users/LUCAS/Desktop/Tanzania/lgacontrols.xlsx")

#variable.names(lgacontrols)
```

# Payments 

`payments_alldrs`: 9 variables. Payments in dollars per DLI between 2015 and 2019, disaggregated at council level (LGA). 

Between 184 and 185 LGA are elegible, although not all of them receive funds. 
Not all DLI are paid across range of years.

`payments_alldlrs.c`: DLI payments are aggregated at council and DLI (losing time dimension) to use in the analysis of DLI 4 - PTR (only data on 2015 and 2019, a before/after).

About DLI 4.2: Average amount received: 82016$, std. dev: 92569; 33 councils received 0. Quartiles: 1st: 14782, 3rd: 115000

DLI 4.2 over time: many councils with 0; year 2018 is the highest avarage: 33880, std. dev 65192. years 2016 and 2017 average lower: 16141, 11207, respectevely.

```{r, payments, warning=F,message=F}

payments_alldlrs <- read_excel("C:/Users/LUCAS/Desktop/Tanzania/ptr/payments-alldlrs.xlsx")

#variable.names(payments_alldlrs)

pander(table(payments_alldlrs$DLI, payments_alldlrs$Year), style = "simple",
      caption = "DLI payments per year - potential councils")

#table(payments_alldlrs$`DLI description`, payments_alldlrs$Year)

#distinct(payments_alldlrs,Region) # 26 regions

#distinct(payments_alldlrs,council) # 184 councils


payments_alldlrs.c<-payments_alldlrs%>%group_by(council,DLI)%>%
summarise(Amount.t=sum(Amount))  #aggregating amount by council, losing time dimension

payments_alldlrs.c%>%filter(DLI==4.2)%>%
  ggplot()+geom_histogram(aes(x=Amount.t),bins = 30)+
  theme(axis.text.y = element_blank(),axis.ticks.y = element_blank())+
  ggtitle("DLI 4.2 payments per council")

pay<-payments_alldlrs.c%>%filter(DLI==4.2)%>%ungroup()%>%
  summarise(count = n(),
              Mean.Amount.t = mean(Amount.t),
              SD.Amount.t = sd(Amount.t),
            `Councils without receiveing`= sum(Amount.t == 0))

pander(pay, style = "simple",
      caption = "Aggregated DLI 4.2 payments - Descriptive statistics")

#payments_alldlrs.c%>%filter(DLI==4.2)%>%ungroup()%>%  summarise(Quartile.Amount.t= quantile(Amount.t, probs = c(0.25, 0.5, 0.75)))

pay2<-payments_alldlrs%>%filter(DLI==4.2)%>%group_by(Year)%>%
  summarise(count = n(),
              Mean.Amount = mean(Amount),
              SD.Amount = sd(Amount),
            `Councils without receiveing`= sum(Amount == 0))

pander(pay2, style = "simple",
      caption = "DLI 4.2 payments per year - Descriptive statistics")            
```

# DLR 4 - Pupil teacher ratio 

Pupil teacher ratio ranges from 0 to 884 studentes per teacher. This suggests measurement errors. Setting outliers at <1.5%  and >98.5%, excluded values are <8.8 and > 113.82.

```{r, ptr and outliers, warning=F,message=F}

ptr_2019_2015 <- read.csv("C:/Users/LUCAS/Desktop/Tanzania/ptr/ptr_2019_2015.csv",na.strings='.')

ptr_2019_2015$ptr<-ptr_2019_2015$Total.Primary/ptr_2019_2015$TotTeach # computing again ptr (to avoid excel csv error)
ptr_2019_2015$pqtr<-ptr_2019_2015$Total.Primary/ptr_2019_2015$totqualteach # computing again ptr (to avoid excel csv error)


pander(summary(ptr_2019_2015$ptr),
        style = "simple",
      caption = "PTR - Descriptive statistics")# range from 0 to 884 - outliers


#sd(ptr_2019_2015$ptr,na.rm = T) # sigma 25.04

outlier_values <- boxplot.stats(ptr_2019_2015$ptr)$out  # outlier ptr values >112
#head(sort(outlier_values))
#quantile(ptr_2019_2015$ptr, probs = seq(0, 1, 1/200),na.rm = T) # outliers at 1.5%  and 98.5%-> <8.8 and >113.82  ?

outlier_values2 <- boxplot.stats(ptr_2019_2015$pqtr)$out  # outlier pqtr values >114
#head(sort(outlier_values2))
#quantile(ptr_2019_2015$pqtr, probs = seq(0, 1, 1/200),na.rm = T) # outliers at 1.5%  and 98.5%-> <9.85 and >128.13  ?

```

```{r, ptr SCHOOL difference between 2019 and 2015, warning=F,message=F}

ptr_2019_2015$SCHNAME<-as.factor(ptr_2019_2015$SCHNAME)

#table(ptr_2019_2015$Duplicate) #13 duplicate

#variable.names(ptr_2019_2015)
ptr_2019_2015<-ptr_2019_2015%>%group_by(council,SCHNAME)%>%filter(Duplicate!="yes")%>%
  mutate(diffence.school.ptr=  ptr - dplyr::lag(ptr,order_by = ï..year) ,
          diffence.school.pqtr= pqtr -dplyr::lag(pqtr,order_by = ï..year)) # pte `19 - `15: negative values are good.

#summary(ptr_2019_2015$diffence.school.ptr) # 18172  schools don't match and measurement eror 
#summary(ptr_2019_2015$diffence.school.pqtr) # 18172  schools don't match and measurement eror
```

``` {r, ptr council, warning=F,message=F}

# money flows at council level, so compare councils

ptr_2019_2015.anova<-ptr_2019_2015%>%
  filter((ptr>8 & ptr<113)&(pqtr>9.85&pqtr<128.13)& Duplicate!="yes")%>% # filtering outliers and duplicated
  mutate(share.ptr = case_when(ptr > 50    ~ 1,
                        ptr < 50    ~ 0)) %>%
  group_by(council,ï..year)%>%      # grouping by year 2015 and 2019 
  summarise(share.sch.not.accept=sum(share.ptr,na.rm = T)/n(),
            ptr.c=mean(ptr,na.rm = T),                 # mean ptr by council/year
            pqtr.c=mean(pqtr,na.rm = T),               # mean pqtr by council/year
            std.tot=sum(Total.Primary,na.rm = T),      # sum of students by council/year 
            teach.tot=sum(TotTeach,na.rm=T),          # sum of teachers by council/year 
            qteach.tot=sum(totqualteach,na.rm=T),     # sum of qualified teachers by council/year
            schools=n(),   # number of schools
    teach.surplus.ideal.distr=((mean(teach.tot,na.rm = T)-(mean(std.tot,na.rm=T)/50))))#(tch - std/50) => + means excess

ptr_2019_2015.anova<-ptr_2019_2015.anova %>%group_by(council)%>%# diff across council and lagged value - neg is good!
           mutate(difference.council.ptr= ptr.c - dplyr::lag(ptr.c,order_by = ï..year),
                  difference.council.pqtr= pqtr.c - dplyr::lag(pqtr.c,order_by = ï..year),
                  dif.std=std.tot-dplyr::lag(std.tot,order_by = ï..year),
                  dif.tch=teach.tot-dplyr::lag(teach.tot,order_by = ï..year),
                  dif.qtch=qteach.tot-dplyr::lag(qteach.tot,order_by = ï..year))

ptr_2019_2015.anova<- ptr_2019_2015.anova %>% rationalize() # remove Inf

ptr_2019_2015.anova$ï..year<-as.factor(ptr_2019_2015.anova$ï..year)

colnames(ptr_2019_2015.anova)[2]<-"year.ptr"

```

PTR is aggregated at LGA level because there is not match of 18172 of council/school names.

Analysing PTR over time (2015 and 2019), we observe median and mean are higher in the in 2019 roughly by 5.5 pupils. 

``` {r, summary ptr, warning=F,message=F}

ptr<-ptr_2019_2015.anova%>%group_by(year.ptr)%>%
    summarise(Median.ptr.c= median(ptr.c),
              Mean.ptr.c = mean(ptr.c),
              SD.ptr.c = sd(ptr.c))

pander(ptr,
        style = "simple",
      caption = "PTR by year without outliers - Descriptive statistics")
```


This is explained by an important raise in students population (15.5% on average) and a smaller increase in teacher population (4.7%).

Total number of students per council across years
``` {r, tables year ptr}
pander(tapply(ptr_2019_2015.anova$std.tot,ptr_2019_2015.anova$year.ptr,summary),
             style = "simple",
      caption = "Total students by year - Descriptive statistics") # important increase on students55807/48421 = 15.2%
```

Total number of teachers per council across years
``` {r, table teach ptr}
pander(tapply(ptr_2019_2015.anova$teach.tot,ptr_2019_2015.anova$year.ptr,summary),
             style = "simple",
      caption = "Total teachers by year - Descriptive statistics") # not so relevant  on teachers 1085.6/1036.6 = 4.7%


```

School PTR across councils have deteriorated between 2015 and 2019. The overall average of schools with a PTR over 50 (which was the standard in 2015) growths from 42.1% to 54.4% and dispersion, measured by the standard deviation, also increases form 23.4% to 26.1%.

The following plot shows the fraction of schools above the acceptable threshold for 2015 (>50 students) in both years, ranging from 0 to 97.25%.

``` {r, plot share schools ptr over 50, warning=F,message=F}

share<-ptr_2019_2015.anova%>%group_by(year.ptr)%>%
    summarise(Median= median(share.sch.not.accept),
              Mean= mean(share.sch.not.accept),
              SD = sd(share.sch.not.accept))
            
pander(share,
             style = "simple",
      caption = "Share of schools with PTR > 50 - Descriptive statistics")

ptr_2019_2015.anova %>% #filter(year.ptr==2015)%>%
  ggplot()+
  geom_point(aes(x=council,y=sort(share.sch.not.accept),
                 group=year.ptr,colour=year.ptr),
             position = "jitter")+
  ylab("Fraction of schools with ptr > 50")+  xlab("Councils")+
  theme(axis.text.x = element_blank(),axis.ticks = element_blank(),panel.background = element_blank())+
  scale_y_continuous(breaks = seq(0,1,.1))

```

An ideal surplus of teachers per council was computed as $\sum Teachers - (\sum Students /50)$, which gives an idea of the ability of the council to achieve equaty in the distribtion of teachers. A major caveat of this calculation relies on the fact that students cannot follow the same ideal distribution due to household location, school resources and population age structure. However, this allows to understand the magnitude of gaps to be covered. 

The following plots shows, for 2015 and 2019, the average PTR per council and the average ideal teacher surplus. The green area capture those councils under the PTR threshold, while the red are those which, having an ideal surplus, are above the PTR cutoff. The yellow area represents those councils that are both above PTR threshold and with teacher's deficit. 



``` {r, plot ptr.c and teach.surplus.ideal.distr, warning=F,message=F}

ptr_2019_2015.anova %>% filter(year.ptr==2015)%>%
  ggplot()+
  geom_point(aes(x=ptr.c,y=teach.surplus.ideal.distr,group=year.ptr,colour=year.ptr),colour="darkblue") +
  #scale_color_manual(values = c("2015" = "darkblue", "2019" = "darkorange"))+
  theme(axis.ticks = element_blank(),panel.background = element_blank())+
       ggtitle("Average PTR and Ideal teacher surplus - 2015")+
  scale_y_continuous(breaks = seq(-1500,1650,300))+xlab("average ptr per council")+
  ylab("average teach surplus ideal per council")+
  scale_x_continuous(breaks = seq(20,200,10))+
  geom_hline(yintercept=0,linetype="dashed", color = "gray")+
  geom_vline(xintercept=35,linetype="dashed", color = "gray")+
    geom_vline(xintercept=50,linetype="dashed", color = "gray")+
  geom_rect(aes(xmin=25, xmax=50, ymin=0, ymax=1700), fill="darkgreen", alpha=.002) +
  geom_rect(aes(xmin=50, xmax=80, ymin=0, ymax=1700), fill="red", alpha=.002) +
  geom_rect(aes(xmin=50, xmax=80, ymin=-1500, ymax=0), fill="yellow", alpha=.002) 


ptr_2019_2015.anova %>% filter(year.ptr==2019)%>%
  ggplot()+
  geom_point(aes(x=ptr.c,y=teach.surplus.ideal.distr,group=year.ptr,colour=year.ptr),colour="black") +
  #scale_color_manual(values = c("2015" = "darkblue", "2019" = "darkorange"))+
  theme(axis.ticks = element_blank(),panel.background = element_blank())+
       ggtitle("Average PTR and Ideal teacher surplus - 2019")+
  scale_y_continuous(breaks = seq(-1500,1650,300))+xlab("average ptr per council")+
  ylab("average teach surplus ideal per council")+
  scale_x_continuous(breaks = seq(20,200,10))+
  geom_hline(yintercept=0,linetype="dashed", color = "gray")+
  geom_vline(xintercept=35,linetype="dashed", color = "gray")+
    geom_vline(xintercept=50,linetype="dashed", color = "gray")+
  geom_rect(aes(xmin=25, xmax=50, ymin=0, ymax=1700), fill="darkgreen", alpha=.002) +
  geom_rect(aes(xmin=50, xmax=80, ymin=0, ymax=1700), fill="red", alpha=.002) +
  geom_rect(aes(xmin=50, xmax=80, ymin=-1500, ymax=0), fill="yellow", alpha=.002) 
```

There is a strong negative linear correlation (-.79 and -.86) across both years. Both tails, in the negative and positive side, show different patterns.

``` {r, cora}
cora<-ptr_2019_2015.anova%>%group_by(year.ptr)%>%
  do(cor=cor(.$ptr.c,.$teach.surplus.ideal.distr,use="pairwise"))

pander(cora,
             style = "simple",
      caption = "Correlation PTR and teacher ideal distribution by council")

```

There is a very strong correlation between average PTR and share of schools with PTR above 50 per council,as shown in the following graph: .95 and .97 in 2015 and 2017. 

``` {r, plot share.sch.not.accept and ptr.c, warning=F,message=F}

cora2<-ptr_2019_2015.anova%>%group_by(year.ptr)%>%
  do(cor=cor(.$ptr.c,.$share.sch.not.accept,use="pairwise"))

pander(cora2,style = "simple",
      caption = "Correlation PTR and share of schools above PTR >50")


ptr_2019_2015.anova %>% #filter(year.ptr==2015)%>%
  ggplot()+
 geom_point(aes(x=ptr.c,y=share.sch.not.accept,group=year.ptr,colour=year.ptr)) +
  scale_color_manual(values = c("2015" = "darkblue", "2019" = "darkorange"))+
         ggtitle("Average PTR and Share of schools PTR > 50")+
  scale_y_continuous(breaks = seq(0,1,.2))+xlab("average ptr per council")+
  ylab("fraction of schools over PTR > 50")+
  scale_x_continuous(breaks = seq(20,80,10))+
  geom_vline(xintercept=35,linetype="dashed", color = "darkred")+
    geom_vline(xintercept=50,linetype="dashed", color = "darkred") #+
  #geom_rect(aes(xmin=25, xmax=50, ymin=0, ymax=1700), fill="darkgreen", alpha=.002) +
 # geom_rect(aes(xmin=50, xmax=80, ymin=0, ymax=1700), fill="red", alpha=.002) +
 # geom_rect(aes(xmin=50, xmax=80, ymin=-1500, ymax=0), fill="yellow", alpha=.002) 

```

Turning to the analysis of PBR, we model a mixed-effects ANOVA to account for between- and within- council mean PTR differences. Onyl the year year and the interaction between year and DLI amount are significant.The relative magnitudes of the sums of squares indicates that the year term explains much more variation of PTR than the interaction term. Plotting the interaction predicted values we observe differences in terms of PTR across years when councils receive smaller values, which become insignificant later. To estimate differences, we use linear mixed-effects models, which are summarised below.

```{r anovas,  warning=F,message=F}

ptr_2019_2015.anova<-ptr_2019_2015.anova  %>%left_join(lgacontrols)

ptr_2019_2015.anova<-ptr_2019_2015.anova%>%
  full_join(payments_alldlrs.c,by="council") %>% filter(DLI==4.2) # ptr is 2015 and 2019 // payment_alldlrs is 2016-2019

ptr_2019_2015.anova$council<-as.factor(ptr_2019_2015.anova$council)

ptr_2019_2015.anova$am.st<-ptr_2019_2015.anova$Amount.t/ptr_2019_2015.anova$std.tot

ptr_2019_2015.anova$am.tea<-ptr_2019_2015.anova$Amount.t/ptr_2019_2015.anova$teach.tot

ptr_2019_2015.anova$dropout_uw2015_pct<-as.numeric(ptr_2019_2015.anova$dropout_uw2015_pct)
ptr_2019_2015.anova$neverenrol_uw2015_pct<-as.numeric(ptr_2019_2015.anova$neverenrol_uw2015_pct)

##

model  <- lm(ptr.c ~ Amount.t*year.ptr+council,
             data = ptr_2019_2015.anova)


# Create a QQ plot of residuals
#ggqqplot(residuals(model))

anova.amount<-aov(ptr.c ~ Amount.t*year.ptr+Error(council/year.ptr), data=ptr_2019_2015.anova,type=3)

#pander(anova_stats(anova.amount))
#summary(anova.amount)

lmer.amount<-lmer(ptr.c ~ Amount.t*year.ptr+(1|council)-1, data=ptr_2019_2015.anova)

pander(anova(lmer.amount),style = "simple",
      caption = "Analysis of Variance - Type 3")

a<-summary(lmer.amount)$coefficients

pander(a,style = "simple",
      caption = "Model parameters")

sjPlot::plot_model(lmer.amount,type="int")

```

We also normalise councils' received amounts by student, such as in $amount/student$ and run the same ANOVA model. In this case, all terms, including the DLI amount, are significant, while the sum of squares suggest the year term is relatively higher in terms of explaining PTR. The  amount/student estimate is significant and shows a negative sign, which suggests an association between amount/student and reducing PTR.

``` {r, am.std anova, warning=F,message=F}

### am.std

model2  <- lm(ptr.c ~ am.st*year.ptr+council,
             data = ptr_2019_2015.anova)

# Create a QQ plot of residuals
#ggqqplot(residuals(model2))


anova.am.st<-aov(ptr.c ~ am.st*year.ptr+Error(council/(Amount.t*year.ptr)), data=ptr_2019_2015.anova,type=3)

#kable(anova_stats(anova.am.st),format = "latex")

#summary(anova.am.st)

lmer.am.st<-lmer(ptr.c ~ am.st*year.ptr+(1|council)-1, data=ptr_2019_2015.anova)

pander(anova(lmer.am.st),style = "simple",
      caption = "Analysis of Variance - Type 3")

b<-summary(lmer.am.st)$coefficients
pander(b,style = "simple",
      caption = "Model parameters")

sjPlot::plot_model(lmer.am.st,type="int")
```


# DLR 6

## National examns

```{r, national exams}

combined_school_level_results_sfna_and_psle <- read_excel("C:/Users/LUCAS/Desktop/Tanzania/combined_school_level_results _sfna_and_psle.xlsx")

LG_names_for_matching_PSLE_with_the_PTR_and_controls_files <- read_excel("C:/Users/LUCAS/Desktop/Tanzania/LG names for matching PSLE with the PTR and controls files.xlsx")

combined_school_level_results_sfna_and_psle<-combined_school_level_results_sfna_and_psle%>%left_join(LG_names_for_matching_PSLE_with_the_PTR_and_controls_files,by=c("LG"="NECTAlganame"))

#variable.names(combined_school_level_results_sfna_and_psle)

#table(combined_school_level_results_sfna_and_psle$year)

#table(combined_school_level_results_sfna_and_psle$exam)

#table(combined_school_level_results_sfna_and_psle$year,combined_school_level_results_sfna_and_psle$exam)

#table(combined_school_level_results_sfna_and_psle$candidates)

#table(combined_school_level_results_sfna_and_psle$council)

combined_school_level_results_sfna_and_psle$exam[combined_school_level_results_sfna_and_psle$exam=="psle"]<-"PSLE"

#combined_school_level_results_sfna_and_psle %>% group_by(year,exam,council)%>%  summarise(score=mean(`school score`))

coral<-combined_school_level_results_sfna_and_psle %>% group_by(exam)%>%
  do(cor=cor(.$candidates,.$`school score`,use="pairwise"))

pander(coral,style="simple",
      caption = "Correlation between # students and school score")

```

```{r, national exams data preparation}

national<-combined_school_level_results_sfna_and_psle %>%filter(exam=="PSLE")  %>%left_join(lgacontrols)%>%
  filter(council!="error" & council!="missing in NECTA data")

payments_alldlrs.y<-payments_alldlrs %>%
  group_by(council, Year)%>%
  summarise(Amount=sum(Amount,na.rm = T))

national<-national%>%
  full_join(payments_alldlrs.y,by=c("council","year"="Year"))

#variable.names(national)

#national%>%group_by(council,year)%>%summarise(a=mean(Amount))%>%ungroup()%>%summarise(b=sum(a,na.rm = T))


```

```{r, descriptive ammount money}

colnames(national)[5]<-"school"
colnames(national)[7]<-"score"
#
#national %>%  group_by(council,year) %>%  summarise( am=mean(Amount))%>%ungroup()%>%summarise(ab=sum(am,na.rm = T))

t<-national %>%
  group_by(council,year) %>%
  mutate(am=mean(Amount,na.rm = T))%>%dplyr::select(council,year,am)%>%distinct()
         
#sum(t$am,na.rm = T)

pander(summary(t$am), style="simple",caption = "Descriptive statistics - Ammount DLR")
pander(tapply(t$am, t$year, summary), style="simple",caption = "Descriptive statistics - Ammount DLR per year")
```

``` {r, plot councils and scores by group of money}

national %>% filter(year>2015)%>%
  group_by(council,year) %>%
  mutate(am=mean(Amount,na.rm = T),
          council.i = case_when(am <= 44815 ~ "less<1st",
                          am >  44815 & am <= 134695  ~ "1st-Mean",
                          am >  134695 & am <= 187638 ~ "Mean-3rd",
                          am >  187638  ~ ">3rd")) %>%
  group_by(council.i,year) %>%
  summarise(council.mean.school.scores = mean(score,na.rm=T))%>%
  ggplot()+geom_line(aes(x=year,y=council.mean.school.scores,
                         group=council.i,
                         colour=council.i))+theme_bw()+
  ggtitle("PSLE average of councils grouped by overall DLR received")+
  ylab("Average of school scores")

```


Fixed effects models at council level - aggregating all money, considering learning outcomes (tests) as a impact.

``` {r, plm fe}

nat.concil<-national %>% 
  group_by(council,year) %>%
  summarise(am=mean(Amount,na.rm = T),
          council.i = case_when(am <= 44815 ~ "less<1st",
                          am >  44815 & am <= 134695  ~ "1st-Mean",
                          am >  134695 & am <= 187638 ~ "Mean-3rd",
                          am >  187638  ~ ">3rd"),
          score=mean(score,na.rm=T))

nat.concil<-nat.concil  %>%left_join(lgacontrols,by="council")

#sum(nat.concil$am,na.rm = T)

plm.fe <- plm(score~am, model = "within", effect = "twoways",
           data = nat.concil, index = c("council","year"))

summary(plm.fe)

summary(fixef(plm.fe, effect="time"))


```

Random effects models at council level


``` {r, random effects}

plm.re <- plm(score~am, model = "random", effect = "twoways",
           data = nat.concil, index = c("council","year"))

summary(plm.re)

punbalancedness(plm.re)

#

#variable.names(nat.concil)
nat.concil$dropout_uw2015_pct<-as.numeric(nat.concil$dropout_uw2015_pct)


```

Random effects models adding covariates (in lme4 - more flexible) - models don't converge

``` {r, using linear lme4}
#
score.re.c<- lmer(score~am+year+pop2019+urbrur+povertyregion+dropout_uw2015_pct+
                      (1+year|council),
                 data=nat.concil)

summary(score.re.c)



```

